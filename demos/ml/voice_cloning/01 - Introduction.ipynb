{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659daee2-84dd-4bc4-b859-cf7fcfafccd9",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "This research fulfills the first promise of Kaia, a Kitchen AI Assistant with the __voice__, the face and the personality of your favorite character. \n",
    "\n",
    "There are many voice cloning models. In my opinion, TortoiseTTS is still unbeatable in terms of how natural it sounds and how well the peculiarities of the person are picked up. However, we cannot use this, or any other complex model, because:\n",
    "* We don't really want a 24/7 tower with heavy GPU to serve a voice assistant exclusively, this is simply too much.\n",
    "* Tortoise may spend 5 minutes to produce the samples.\n",
    "* If we voice clone each time from scratch, the result may be wrong on some samples. \n",
    "\n",
    "So instead of voice cloning each time, we want to fine-tune the pretrained model that is capable enough to produce a human, non-robotic-like voice, but small enough to run on CPU machine in reasonable time. There are two well-known options: YourTTS and VITS.\n",
    "\n",
    "For most of the time in this research I tried to fine-tune YourTTS, because it's faster. However, there are problems that in the end made me switch to VITS:\n",
    "\n",
    "* YourTTS training is unstable. On the very same data, sometimes it works well, sometimes it doesn't work at all.\n",
    "* YourTTS is trained on letters, not phonems. So my model was in the end pronouncing \"minutes\" like \"mi-NU-tes\", with problems on \"beige\" and \"chaos\" words as well.\n",
    "\n",
    "VITS is slower on inference, but still far from the pain point. The quality of VITS is same as YourTTS. But VITS is trained on phonemes and uses espeak to convert words to phonemes, thus eliminating the pronounciation problems. \n",
    "\n",
    "However, the traces of YourTTS can still be seen in the process, e.g. in Dataset building, as well as in the recommendations on the training data volumes: it might happen that lower volumes and simpler dataset creation procedures are valid as well.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The workflow is:\n",
    "\n",
    "1. Create a good textual dataset that well represents phonemes/letters of English. This should be done only once per language. \n",
    "2. Collect enough of samples for your character so TortoiseTTS could produce their voice.\n",
    "3. Use Tortoise to generate enough of voicelines from texts [1] and samples [2]\n",
    "4. Annotate the voicelines\n",
    "5. Train VITS on the voicelines [5] with CoquiTTS, an amazing framework to train voice models.\n",
    "6. Evaluate the results and maybe go to step [3]\n",
    "7. Export the model so the BrainBox could use it in the decider.\n",
    "\n",
    "I must say that every step was a huge pain. So many problems arised from such insignificant things! I really hope this guide will simplify things for you so you don't have to step on all these rakes yourself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
