{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30564f97-d327-4fba-9f6a-f4828ef2fdc5",
   "metadata": {},
   "source": [
    "## Preparing samples for generation\n",
    "\n",
    "First, you need to find samples of your voice: 8-10 files, 3-4 seconds each is perfectly enough. Actually, even 3-4 files might be enough, the output really stabilizes rapidly.\n",
    "\n",
    "The guidelines on the samples selections:\n",
    "* Try to use the voicelines from computer games. They don't have background noise and music\n",
    "* Don't try to pick the most expressive samples. For some reasons, TortoiseTTS exagregates the expressiveness, so you may end up with something absurd.\n",
    "* Small background noise, like a single footstep, is okay\n",
    "* Effects on voice which they use e.g. for Death Prophet in Dota, are not okay. Tortoise wasn't really able to pick up the voice in this case.\n",
    "* You must normalize the volume. Too loud samples cause TortoiseTTS to produce white noise, screaming or other irrelevant outputs. You can use `kaia.ml.voice_cloning.data_prep.volume_normalization` to do this. \n",
    "* For samples with heavy background noise and backgound music, you might be successfull if you first do a cleaning (separation), using, e.g.\n",
    "\n",
    "I will use Lina's voice from Dota2. I was actually extremely lucky with this voice, it has perfect everything: intotations, volume, etc. Unfortunately, my experience shows that not all the voices, even from computer games, are that good, and many of them needs some hacking. Moreover, for some voices Tortoise seems to work generally worse, no matter what you do with this voice.\n",
    "\n",
    "In case you're preparing samples from e.g. Youtube video files: I wasn't able to quickly find a free utility that would allow you to select fragment from a videofile and export the audio from the fragment to an audiofile quickly, in one-click. So I designed the following pipeline for that:\n",
    "1. e.g. Kdenlive to cut the fragments and remove bad fragments.\n",
    "2. keep good fragments apart with >2 seconds pause between them\n",
    "3. Extract `wav` file from the resulting videofile\n",
    "4. use `kaia.ml.voice_cloning.data_prep.audio_cutter` to cut these audiofiles to individual files.\n",
    "\n",
    "Now, let's assume you already have the samples, and do an upsampling: generating voicelines with TortoiseTTS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbebd9e-9a16-4f9a-862b-b4669e82f35a",
   "metadata": {},
   "source": [
    "First, you need to export samples in Tortoise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ffb559-86a6-437d-912d-e3b1b3e6d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaia.brainbox.deciders.docker_based import TortoiseTTSSettings\n",
    "from pathlib import Path\n",
    "\n",
    "settings = TortoiseTTSSettings()\n",
    "settings.export_voice_for_tortoise('lina', Path('files/voice'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a44ea0-4074-45cc-bb63-a9ac1d5f4d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': 'id_0a62e2ce86124bbf80a5397af2d6a61a', 'decider': 'TortoiseTTS', 'arguments': {'voice': 'lina', 'text': 'Trollocs were usually cowards in their way, preferring strong odds and easy kills.'}, 'dependencies': None, 'back_track': None, 'batch': None, 'decider_method': None, 'decider_parameters': None},\n",
       " {'id': 'id_0063c929b8ab424b8872808f22393f06', 'decider': 'TortoiseTTS', 'arguments': {'voice': 'lina', 'text': 'The Deathwatch Guard has charge of my safety, but you have charge of the defense of this camp.'}, 'dependencies': None, 'back_track': None, 'batch': None, 'decider_method': None, 'decider_parameters': None})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaia.ml.voice_cloning.data_prep.task_generator import generate_tasks\n",
    "from kaia.infra import Loc, FileIO\n",
    "\n",
    "golden_set = FileIO.read_json('files/golden_set.json')\n",
    "texts = [s['text'] for s in golden_set]\n",
    "tasks = generate_tasks(texts[:3], ['lina'])\n",
    "\n",
    "tasks.intermediate_tasks[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c103da01-0b87-4551-a177-39f0833393c1",
   "metadata": {},
   "source": [
    "Afterwards, you need to start BrainBox server, add the tasks, wait for the results (it can take days for large amounts) and download the results.\n",
    "\n",
    "```python\n",
    "from kaia.brainbox import BrainBox\n",
    "\n",
    "api = BrainBox().create_api('127.0.0.1')\n",
    "api.add(tasks)\n",
    "\n",
    "api.download(api.get_result('id_09fa356482dd442ca0a5697b3efa9294'),  Path('files/voicelines.zip')) # paste the ID of Collector's task here\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
