{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbfcf532",
   "metadata": {},
   "source": [
    "Rhasspy is a magnificent voice management software. It's open-source, multi-platform and allows API to:\n",
    "\n",
    "* Manage mic and speakers\n",
    "* Runs speech recognition that is based on predefined sentences\n",
    "* Has a text-to-speech features, although it's less impressive\n",
    "* Manages wake-up-word\n",
    "\n",
    "In other words, Rhasspy is a solid foundation for our home assistant. In the previous versions of Kaia, Rhasspy was used as a main control over all audiosubsystem, but later other Kaia's subsystems took over, so Rhasspy is used only for NLU.\n",
    "\n",
    "Simplest way to install it is Docker. You need to have Docker on your local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa4e77e2-e5c0-4a90-aa1c-c6c181203724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaia.brainbox.deciders.docker_based import RhasspyInstaller, RhasspySettings\n",
    "\n",
    "installer = RhasspyInstaller(RhasspySettings())\n",
    "rhasspy_api = installer.run_in_any_case_and_return_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0d82f",
   "metadata": {},
   "source": [
    "This will download everything that is needed, sets the server up with Kaldi/Fssticuffs NLU. \n",
    "\n",
    "You only need to do it once, as Rhasspy adds itself to the docker startup and starts atomatically when the system boots (or, in Windows, when Docker starts).\n",
    "\n",
    "The command _will not_ connect Rhasspy to your microphone or speakers, as we are not intended to use this functionality right now.\n",
    "\n",
    "You can now open Rhasspy and see what's there. You won't need to configure it manually, as in the following cells we'll configure Rhasspy via api."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf85d4c9-cf01-4a26-ba39-6cd674d429ae",
   "metadata": {},
   "source": [
    "Now let's try Rhasspy in action. First, let's reproduce steps from the previous notebooks and create and audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba643b81-20ed-4eec-8133-2e5149094ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4604d5c282b4653900ade1c71162ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Audio(value=b'RIFFD\\x1c\\x02\\x00WAVEfmt \\x10\\x00\\x00\\x00\\x01\\x00\\x01\\x00\"V\\x00\\x00D\\xac\\x00\\x00\\x02\\x00\\x10\\x00â€¦"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaia.brainbox import BrainBoxTask, BrainBoxTaskPack, DownloadingPostprocessor, BrainBox\n",
    "from kaia.infra import FileIO\n",
    "from ipywidgets import Audio\n",
    "from kaia.avatar.server.dubbing_service import BrainBoxDubbingService\n",
    "from kaia.brainbox import BrainBox\n",
    "from kaia.avatar.dub.languages.en import *\n",
    "\n",
    "def task_generator(text, voice):\n",
    "    return BrainBoxTaskPack(\n",
    "        BrainBoxTask(\n",
    "            id = BrainBoxTask.safe_id(), \n",
    "            decider='OpenTTS', \n",
    "            arguments=dict(voice='coqui-tts:en_vctk', lang='en', speakerId=voice, text=text)\n",
    "            ),\n",
    "        (),\n",
    "        DownloadingPostprocessor(take_element_before_downloading=0, opener=FileIO.read_bytes)\n",
    "    )\n",
    "\n",
    "template = Template(\n",
    "    'Set the timer for {hours} {hours_word} and {minutes} {minutes_word}',\n",
    "    hours = CardinalDub(0, 24),\n",
    "    hours_word = PluralAgreement('hours', 'hour', 'hours'),\n",
    "    minutes = CardinalDub(0, 60),\n",
    "    minutes_word = PluralAgreement('minutes', 'minute', 'minutes')\n",
    ").with_name('set_the_timer')\n",
    "\n",
    "with BrainBox().create_test_api() as bb_api:\n",
    "    service = BrainBoxDubbingService(task_generator, bb_api)\n",
    "    utterance = template.utter(dict(hours=11, minutes=1))\n",
    "    voiceover = service.dub_string(utterance.to_str(), 'p225').data\n",
    "Audio(value=voiceover, autoplay = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5966a931-6a66-49ee-a58e-bed4db7af185",
   "metadata": {},
   "source": [
    "Run these cells to train Rhasspy on the template of the utterance (currently only one) and recognize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7c2e92b-dc2a-4360-98b4-b0348732eba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_the_timer {'minutes': 1, 'hours': 11}\n"
     ]
    }
   ],
   "source": [
    "rhasspy_api.setup_intents([template])\n",
    "rhasspy_api.train()\n",
    "recognized_utterance = rhasspy_api.recognize(voiceover)\n",
    "print(recognized_utterance.template.name, recognized_utterance.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e2307d-8f4f-437c-a62b-217704b47341",
   "metadata": {},
   "source": [
    "So, it recognizes the file correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb4b4d-b41e-4a3b-ad76-8a458ff8a546",
   "metadata": {},
   "source": [
    "Then, we can use the test on the larger scale. \n",
    "First, we use predefined `Intents` that contain various intents.\n",
    "Second, we use TestingTools to generate lots of variants for the template with different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5189b44b-2a47-48e2-9f27-c1a9c62cce80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>true_intent</th>\n",
       "      <th>true_value</th>\n",
       "      <th>recognition_obj</th>\n",
       "      <th>parsed_intent</th>\n",
       "      <th>parsed_value</th>\n",
       "      <th>failure</th>\n",
       "      <th>match_intent</th>\n",
       "      <th>match_keys</th>\n",
       "      <th>match_values</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>kaia.avatar.dub.sandbox.intents.Intents.yes</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sure</td>\n",
       "      <td>kaia.avatar.dub.sandbox.intents.Intents.yes</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go on</td>\n",
       "      <td>kaia.avatar.dub.sandbox.intents.Intents.yes</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No.</td>\n",
       "      <td>kaia.avatar.dub.sandbox.intents.Intents.no</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop!</td>\n",
       "      <td>kaia.avatar.dub.sandbox.intents.Intents.no</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>null</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       s                                  true_intent true_value  ... match_keys match_values  match\n",
       "0    Yes  kaia.avatar.dub.sandbox.intents.Intents.yes         {}  ...      False        False  False\n",
       "1   Sure  kaia.avatar.dub.sandbox.intents.Intents.yes         {}  ...      False        False  False\n",
       "2  Go on  kaia.avatar.dub.sandbox.intents.Intents.yes         {}  ...      False        False  False\n",
       "3    No.   kaia.avatar.dub.sandbox.intents.Intents.no         {}  ...      False        False  False\n",
       "4  Stop!   kaia.avatar.dub.sandbox.intents.Intents.no         {}  ...      False        False  False\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from kaia.avatar.dub.sandbox import Intents\n",
    "from kaia.avatar.dub.languages.en import TestingTools\n",
    "import pandas as pd\n",
    "from kaia.infra import FileIO\n",
    "from pathlib import Path\n",
    "\n",
    "tmp_folder = Path('rhasspy_test_files')\n",
    "os.makedirs(tmp_folder, exist_ok=True)\n",
    "samples_path = tmp_folder/'samples.pkl'\n",
    "\n",
    "if not samples_path.is_file():\n",
    "    test = TestingTools(Intents.get_templates(), 100)\n",
    "    FileIO.write_pickle(test, samples_path)\n",
    "else:\n",
    "    test = FileIO.read_pickle(samples_path)\n",
    "    \n",
    "TestingTools.samples_to_df(test.samples).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64544adf-1bf9-4cda-846f-84540cc1a925",
   "metadata": {},
   "source": [
    "We now need to build voice overs for all of these utterances. Here, a MediaLibrary will be very handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b51583c-bdd3-48e1-89e6-4361e99415db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "media_library_path = Path(tmp_folder/'rhasspy_test_voiceover.zip')\n",
    "\n",
    "def create_voiceover_task(samples):\n",
    "    tasks = []\n",
    "    tags = {}\n",
    "    dependencies = {}\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        id = BrainBoxTask.safe_id()\n",
    "        tasks.append(BrainBoxTask(id=id, decider='OpenTTS', arguments=dict(text=sample.s, voice='coqui-tts:en_vctk', lang='en', speakerId='p225')))\n",
    "        dependencies[id] = id\n",
    "        tags[id] = dict(sample_id=i, s=sample.s)\n",
    "    \n",
    "    voiceover_task = BrainBoxTask(id = BrainBoxTask.safe_id(), decider='Collector', arguments=dict(tags=tags), dependencies=dependencies)\n",
    "    return BrainBoxTaskPack(voiceover_task, tasks, DownloadingPostprocessor())\n",
    "\n",
    "\n",
    "if not media_library_path.is_file():\n",
    "    with BrainBox().create_test_api() as api:\n",
    "        task = create_voiceover_task(test.samples)\n",
    "        path = api.execute(task)\n",
    "        shutil.copy(path, media_library_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a335886-4c52-40be-9955-359f8ae3f8ad",
   "metadata": {},
   "source": [
    "Let's browse what's media library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b75fbcc-d8dd-4b9b-a08c-acecb579328a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>s</th>\n",
       "      <th>option_index</th>\n",
       "      <th>filename</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>job_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>45e5b866-7aae-4a03-a6d6-e96e2962cc4f.wav</td>\n",
       "      <td>2024-02-14 21:07:00.607087</td>\n",
       "      <td>id_143480d71fc24f128f0368775e2baec6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sure</td>\n",
       "      <td>0</td>\n",
       "      <td>bc0aa61a-578c-4118-9521-60effbeabc0d.wav</td>\n",
       "      <td>2024-02-14 21:07:00.607087</td>\n",
       "      <td>id_17eb427a791e40b1868c3cb4d5b99eb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Go on</td>\n",
       "      <td>0</td>\n",
       "      <td>37a613f9-ab84-4ccc-b6bd-0977b5163ac9.wav</td>\n",
       "      <td>2024-02-14 21:07:00.607087</td>\n",
       "      <td>id_786f1043c78d4a22bb5642a6d7ba25e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>No.</td>\n",
       "      <td>0</td>\n",
       "      <td>5ffff3d8-579f-47c7-8992-b584e9b1e8c9.wav</td>\n",
       "      <td>2024-02-14 21:07:00.607087</td>\n",
       "      <td>id_b3909ad891134785ac7fa15020c8565e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Stop!</td>\n",
       "      <td>0</td>\n",
       "      <td>122a6140-45df-436d-b981-28f999f89192.wav</td>\n",
       "      <td>2024-02-14 21:07:00.607087</td>\n",
       "      <td>id_faf9e08c4346483e97620b48d2cc9a46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id      s  ...                  timestamp                               job_id\n",
       "0          0    Yes  ... 2024-02-14 21:07:00.607087  id_143480d71fc24f128f0368775e2baec6\n",
       "1          1   Sure  ... 2024-02-14 21:07:00.607087  id_17eb427a791e40b1868c3cb4d5b99eb7\n",
       "2          2  Go on  ... 2024-02-14 21:07:00.607087  id_786f1043c78d4a22bb5642a6d7ba25e1\n",
       "3          3    No.  ... 2024-02-14 21:07:00.607087  id_b3909ad891134785ac7fa15020c8565e\n",
       "4          4  Stop!  ... 2024-02-14 21:07:00.607087  id_faf9e08c4346483e97620b48d2cc9a46\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kaia.brainbox import MediaLibrary\n",
    "\n",
    "lib = MediaLibrary.read(media_library_path)\n",
    "lib.to_df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4453836-e123-4647-ae9a-df2f96b682ba",
   "metadata": {},
   "source": [
    "Now, we will feed all the sound files from media library to RhasspyAPI and recognize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8faab1f-a92e-4cf6-b3fd-039424aa6f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_path = tmp_folder/'test_results.pkl'\n",
    "\n",
    "if not test_result_path.is_file():\n",
    "    lib = MediaLibrary.read(media_library_path)\n",
    "    sample_index_to_file = {record.tags['sample_id'] : record for record in lib.records}\n",
    "    rhasspy_api = RhasspyAPI(ADDRESS, test.intents)\n",
    "    rhasspy_api.train()\n",
    "    test_result = test.test_voice(sample_index_to_file, rhasspy_api)\n",
    "    FileIO.write_pickle(test_result, test_result_path)\n",
    "else:\n",
    "    test_result = FileIO.read_pickle(test_result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756e6fd-c064-4c5a-8c96-026ecc3823d2",
   "metadata": {},
   "source": [
    "Let's see some stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46786bd9-e898-47a3-8914-011d793c8c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.7870967741935484)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = test.samples_to_df(test_result)\n",
    "df.match_intent.mean(), df.match_values.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972f9bbf-056a-49be-bc2e-e47fc4b9953c",
   "metadata": {},
   "source": [
    "## Notes on Rhasspy/TTS test\n",
    "\n",
    "Using Rhasspy to test TTS is a perfect way to see flaws in the TTS solution. This was the way how we realized that using TortoiseTTS to produce fragments and then combine these fragmets is not really a viable option. Moreover, we discovered some fixable issues as well:\n",
    "\n",
    "* the upper bounds of string to voiceover with Tortoise: around 60-70 characters. Sometimes, much longer strings can be processed, but sometimes no.\n",
    "\n",
    "* that sequences like \"six, sixteenth, sixth, sixtieth, sixty, tenth\" are not the best way to organize the voiceover, as TortoiseTTS fails to pronounce \"tenth\" in this case.\n",
    "\n",
    "* How to cut sequence like \"three, four\" into fragments. It appears the correct cut is \"three, \" and \"four\". \"three\"/\"four\" will lose the ending of \"three\", and \"three,\"/\" four\" will add a noise to the beginning of \"four\". Unfortunately, there is no pause tag in TortoiseTTS that could improve this even further.\n",
    "\n",
    "Moreover, used such analysis to understand, which fragments need to be re-generated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
